{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5de5ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected unindent (<ipython-input-7-c0c660ac852d>, line 126)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-c0c660ac852d>\"\u001b[1;36m, line \u001b[1;32m126\u001b[0m\n\u001b[1;33m    print(\"Scraping completed!\")\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected unindent\n"
     ]
    }
   ],
   "source": [
    "# # Import necessary libraries\n",
    "# from selenium import webdriver  # For automating web browser interactions\n",
    "# from selenium.webdriver.common.by import By  # For locating elements on web pages\n",
    "# from bs4 import BeautifulSoup  # For parsing HTML and XML documents\n",
    "# import time  # For adding delays in the script\n",
    "# import warnings  # For managing warning messages\n",
    "# import pandas as pd  # For working with data in tabular format\n",
    "# from tqdm import tqdm  # For displaying progress bars\n",
    "# import csv  # For reading and writing CSV files\n",
    "# import random  # For generating random numbers\n",
    "# import datetime  # For working with dates and times\n",
    "\n",
    "# # Ignore any warning messages\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Read the Excel file containing company names into a DataFrame\n",
    "# df = pd.read_excel(\"Company_names.xlsx\")\n",
    "\n",
    "# # Display the first 10 rows of the DataFrame\n",
    "# df.head(10)\n",
    "\n",
    "# # Read the LinkedIn authentication information (li_at cookie) from a text file\n",
    "# with open(\"config.txt\", 'r', encoding=\"utf-8\") as f1:\n",
    "#     lines = f1.readlines()\n",
    "# li_at = lines[0]\n",
    "\n",
    "# # Define the LinkedIn cookie\n",
    "# cookies = {\n",
    "#     'name': 'li_at',\n",
    "#     'value': li_at,\n",
    "#     'domain': '.linkedin.com',\n",
    "# }\n",
    "\n",
    "# # Initialize a Chrome WebDriver\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "# # Navigate to the LinkedIn login page\n",
    "# driver.get(\"https://www.linkedin.com\")\n",
    "# time.sleep(random.randint(60, 65))\n",
    "# # Maximize the browser window\n",
    "# driver.maximize_window()\n",
    "\n",
    "# # Add the LinkedIn cookie to the WebDriver session\n",
    "# driver.add_cookie(cookies)\n",
    "\n",
    "# # Create an empty DataFrame to store company information\n",
    "# transfer_sheet = pd.DataFrame(columns=[\"Company Name\", \"Job Role\", \"Job Description\"])\n",
    "\n",
    "# # Initialize a counter variable\n",
    "# c = 0\n",
    "\n",
    "# # Iterate through each company name in the DataFrame\n",
    "# for cn in df[\"Name\"]:\n",
    "#     # Construct the search URL for the company on LinkedIn\n",
    "#     search_url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3856839658&keywords={cn}%20jobs&origin=SWITCH_SEARCH_VERTICAL\"\n",
    "    \n",
    "#     # Navigate to the search URL\n",
    "#     driver.get(search_url)\n",
    "    \n",
    "#     # Add a random delay to simulate human-like behavior\n",
    "#     time.sleep(random.randint(2, 5))\n",
    "    \n",
    "#     try:\n",
    "#         # Find the first search result link for the company\n",
    "#         jc = driver.find_elements(By.CSS_SELECTOR, \".reusable-search__result-container a.app-aware-link\")\n",
    "#         elems = list(jc)\n",
    "#         lnks = elems[0].get_attribute('href') \n",
    "        \n",
    "        \n",
    "#         # Find all elements matching the specified CSS selector\n",
    "#         job_elements = driver.find_elements_by_css_selector('.scaffold-layout__list-container li[data-occludable-job-id]')\n",
    "\n",
    "#         # Iterate over each element and extract the 'data-occludable-job-id' attribute\n",
    "#         for item in job_elements:\n",
    "#             job_id = item.get_attribute('data-occludable-job-id')\n",
    "#             print('Job ID:', job_id)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         # Navigate to the company page\n",
    "#         driver.get(lnks)\n",
    "        \n",
    "#         # Add a random delay\n",
    "#         time.sleep(random.randint(3, 7))\n",
    "        \n",
    "#         try:\n",
    "#             # Navigate to the \"About\" section of the company page\n",
    "#             a = \"\"\n",
    "#             for i in driver.find_elements(By.CSS_SELECTOR, \".org-page-navigation__item a\"):\n",
    "#                 x1 = i.get_attribute('href')\n",
    "#                 if 'about' in str(x1):\n",
    "#                     a = x1\n",
    "#             driver.get(a)\n",
    "#         except:\n",
    "#             print(\"Link not Found\")\n",
    "        \n",
    "#         # Add a random delay\n",
    "#         time.sleep(random.randint(4, 9))\n",
    "        \n",
    "#         # Extract information about the company\n",
    "#         b = \"\"\n",
    "#         elem2 = driver.find_elements(By.CSS_SELECTOR, \".overflow-hidden dd\")\n",
    "#         for k in elem2:\n",
    "#             b += \" \" + k.text\n",
    "        \n",
    "#         # Store the extracted information in the DataFrame\n",
    "#         transfer_sheet.loc[c] = [cn, b]\n",
    "#         c += 1\n",
    "        \n",
    "#         # Write the DataFrame to an Excel file\n",
    "#         transfer_sheet.to_excel(r\"C:\\Users\\91700\\Desktop\\DT\\Scrapper\\data.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "        \n",
    "#         # Add a random delay\n",
    "#         time.sleep(random.randint(1, 5))\n",
    "    \n",
    "#     except:\n",
    "#         # If company information cannot be retrieved, mark it as \"No results\" in the DataFrame\n",
    "#         transfer_sheet.loc[c] = [cn, \"No results\"]\n",
    "#         transfer_sheet.to_excel(r\"C:\\Users\\91700\\Desktop\\DT\\Scrapper\\data.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "\n",
    "# # End of the loop\n",
    "\n",
    "# # Display completion message\n",
    "# print(\"Scraping completed!\")\n",
    "# # Close the WebDriver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecce3a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: failed to change window state to 'maximized', current state is 'minimized'\n  (Session info: chrome=124.0.6367.158)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7D8591562+60802]\n\t(No symbol) [0x00007FF7D850AC62]\n\t(No symbol) [0x00007FF7D83C7CE4]\n\t(No symbol) [0x00007FF7D83A224A]\n\t(No symbol) [0x00007FF7D83A0688]\n\t(No symbol) [0x00007FF7D839EBF9]\n\t(No symbol) [0x00007FF7D84715E9]\n\t(No symbol) [0x00007FF7D843AB7A]\n\t(No symbol) [0x00007FF7D845A224]\n\t(No symbol) [0x00007FF7D843A923]\n\t(No symbol) [0x00007FF7D8408FEC]\n\t(No symbol) [0x00007FF7D8409C21]\n\tGetHandleVerifier [0x00007FF7D88941FD+3217949]\n\tGetHandleVerifier [0x00007FF7D88D6197+3488183]\n\tGetHandleVerifier [0x00007FF7D88CF11F+3459391]\n\tGetHandleVerifier [0x00007FF7D864B926+823622]\n\t(No symbol) [0x00007FF7D8515FFF]\n\t(No symbol) [0x00007FF7D8510F24]\n\t(No symbol) [0x00007FF7D85110B2]\n\t(No symbol) [0x00007FF7D8501904]\n\tBaseThreadInitThunk [0x00007FFC64977344+20]\n\tRtlUserThreadStart [0x00007FFC669826B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7e760afa9b12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Maximize the browser window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Add the LinkedIn cookie to the WebDriver session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mmaximize_window\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;34m\"\"\"Maximizes the current window that webdriver is using.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW3C_MAXIMIZE_WINDOW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfullscreen_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: failed to change window state to 'maximized', current state is 'minimized'\n  (Session info: chrome=124.0.6367.158)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7D8591562+60802]\n\t(No symbol) [0x00007FF7D850AC62]\n\t(No symbol) [0x00007FF7D83C7CE4]\n\t(No symbol) [0x00007FF7D83A224A]\n\t(No symbol) [0x00007FF7D83A0688]\n\t(No symbol) [0x00007FF7D839EBF9]\n\t(No symbol) [0x00007FF7D84715E9]\n\t(No symbol) [0x00007FF7D843AB7A]\n\t(No symbol) [0x00007FF7D845A224]\n\t(No symbol) [0x00007FF7D843A923]\n\t(No symbol) [0x00007FF7D8408FEC]\n\t(No symbol) [0x00007FF7D8409C21]\n\tGetHandleVerifier [0x00007FF7D88941FD+3217949]\n\tGetHandleVerifier [0x00007FF7D88D6197+3488183]\n\tGetHandleVerifier [0x00007FF7D88CF11F+3459391]\n\tGetHandleVerifier [0x00007FF7D864B926+823622]\n\t(No symbol) [0x00007FF7D8515FFF]\n\t(No symbol) [0x00007FF7D8510F24]\n\t(No symbol) [0x00007FF7D85110B2]\n\t(No symbol) [0x00007FF7D8501904]\n\tBaseThreadInitThunk [0x00007FFC64977344+20]\n\tRtlUserThreadStart [0x00007FFC669826B1+33]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from selenium import webdriver  # For automating web browser interactions\n",
    "from selenium.webdriver.common.by import By  # For locating elements on web pages\n",
    "from bs4 import BeautifulSoup  # For parsing HTML and XML documents\n",
    "import time  # For adding delays in the script\n",
    "import warnings  # For managing warning messages\n",
    "import pandas as pd  # For working with data in tabular format\n",
    "from tqdm import tqdm  # For displaying progress bars\n",
    "import csv  # For reading and writing CSV files\n",
    "import random  # For generating random numbers\n",
    "import datetime  # For working with dates and times\n",
    "\n",
    "# Ignore any warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read the Excel file containing company names into a DataFrame\n",
    "df = pd.read_excel(\"Company_names.xlsx\")\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.head(10)\n",
    "\n",
    "# Read the LinkedIn authentication information (li_at cookie) from a text file\n",
    "with open(\"config.txt\", 'r', encoding=\"utf-8\") as f1:\n",
    "    lines = f1.readlines()\n",
    "li_at = lines[0]\n",
    "\n",
    "# Define the LinkedIn cookie\n",
    "cookies = {\n",
    "    'name': 'li_at',\n",
    "    'value': li_at,\n",
    "    'domain': '.linkedin.com',\n",
    "}\n",
    "\n",
    "# Initialize a Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the LinkedIn login page\n",
    "driver.get(\"https://www.linkedin.com\")\n",
    "time.sleep(random.randint(60, 65))\n",
    "# Maximize the browser window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Add the LinkedIn cookie to the WebDriver session\n",
    "driver.add_cookie(cookies)\n",
    "\n",
    "# Create an empty DataFrame to store company information\n",
    "transfer_sheet = pd.DataFrame(columns=[\"Company Name\", \"Job Role\", \"Job Description\"])\n",
    "\n",
    "# Initialize a counter variable\n",
    "c = 0\n",
    "\n",
    "# Iterate through each company name in the DataFrame\n",
    "for cn in df[\"Name\"]:\n",
    "    # Construct the search URL for the company on LinkedIn\n",
    "    search_url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3856839658&keywords={cn}%20jobs&origin=SWITCH_SEARCH_VERTICAL\"\n",
    "    \n",
    "    # Navigate to the search URL\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Add a random delay to simulate human-like behavior\n",
    "    time.sleep(random.randint(2, 5))\n",
    "    \n",
    "    \n",
    "    # Find all elements matching the specified CSS selector\n",
    "    job_elements = driver.find_elements(By.CSS_SELECTOR,\".scaffold-layout__list-container li[data-occludable-job-id]\")\n",
    "\n",
    "    # Iterate over each element and extract the 'data-occludable-job-id' attribute\n",
    "    for item in job_elements:\n",
    "        job_id = item.get_attribute('data-occludable-job-id')\n",
    "        url=f\"https://www.linkedin.com/jobs/view/{job_id}/?eBP=NON_CHARGEABLE_CHANNEL&refId=y33Dar2%2Fd7Ug6IIJOMnUyg%3D%3D&trackingId=GjIBF2h2spZFKbIyLF6%2FWg%3D%3D&trk=flagship3_search_srp_jobs\"\n",
    "        driver.get(url)\n",
    "        time.sleep(random.randint(15, 20))\n",
    "        \n",
    "        # Find the element by its ID or any other suitable method\n",
    "        \n",
    "        element1 = driver.find_element(By.ID, \"ember45\") # Assuming 'ember45' is the ID of the element\n",
    "\n",
    "        # Extract the text from the element\n",
    "        role = element1.text\n",
    "        \n",
    "        # Let's say 'element' is the WebElement you want to extract text from\n",
    "        element2 = driver.find_element(By.CSS_SELECTOR, \".mt4\")\n",
    "\n",
    "        # Extract the text from the element\n",
    "        jod_descriptions = element2.text\n",
    "        \n",
    "        \n",
    "        # Store the extracted information in the DataFrame\n",
    "        transfer_sheet.loc[c] = [cn, role, jod_descriptions]\n",
    "        c += 1\n",
    "        \n",
    "        # Write the DataFrame to an Excel file\n",
    "        transfer_sheet.to_excel(r\"C:\\Users\\91700\\Desktop\\DT\\Scrapper\\data.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "        \n",
    "        # Add a random delay\n",
    "        time.sleep(random.randint(10, 15))\n",
    "        \n",
    "\n",
    "            \n",
    "# Display completion message\n",
    "print(\"Scraping completed!\")\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec51f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Company Name Job Role                                    Job Description\n",
      "0       Google           Cloud Sales Resident, Cloud Academy, Early Car...\n",
      "  Company Name Job Role                                    Job Description\n",
      "0       Google           Cloud Sales Resident, Cloud Academy, Early Car...\n",
      "1       Google           E2E Offer letter variations India\\nGoogle Oper...\n",
      "  Company Name Job Role                                    Job Description\n",
      "0       Google           Cloud Sales Resident, Cloud Academy, Early Car...\n",
      "1       Google           E2E Offer letter variations India\\nGoogle Oper...\n",
      "2       Google           Business Analyst, Youtube Trust and Safety \\nG...\n",
      "  Company Name Job Role                                    Job Description\n",
      "0       Google           Cloud Sales Resident, Cloud Academy, Early Car...\n",
      "1       Google           E2E Offer letter variations India\\nGoogle Oper...\n",
      "2       Google           Business Analyst, Youtube Trust and Safety \\nG...\n",
      "3       Google           E2E Research Analyst - TEST-REC-IND-001\\nGoogl...\n",
      "  Company Name Job Role                                    Job Description\n",
      "0       Google           Cloud Sales Resident, Cloud Academy, Early Car...\n",
      "1       Google           E2E Offer letter variations India\\nGoogle Oper...\n",
      "2       Google           Business Analyst, Youtube Trust and Safety \\nG...\n",
      "3       Google           E2E Research Analyst - TEST-REC-IND-001\\nGoogl...\n",
      "4       Google           E2E IJP Offer letter variations India\\nGoogle ...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from selenium import webdriver  # For automating web browser interactions\n",
    "from selenium.webdriver.common.by import By  # For locating elements on web pages\n",
    "import time  # For adding delays in the script\n",
    "import warnings  # For managing warning messages\n",
    "import pandas as pd  # For working with data in tabular format\n",
    "import random  # For generating random numbers\n",
    "\n",
    "# Ignore any warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read the Excel file containing company names into a DataFrame\n",
    "df = pd.read_excel(\"Company_names.xlsx\")\n",
    "\n",
    "# Read the LinkedIn authentication information (li_at cookie) from a text file\n",
    "with open(\"config.txt\", 'r', encoding=\"utf-8\") as f1:\n",
    "    lines = f1.readlines()\n",
    "li_at = lines[0]\n",
    "\n",
    "# Define the LinkedIn cookie\n",
    "cookies = {\n",
    "    'name': 'li_at',\n",
    "    'value': li_at,\n",
    "    'domain': '.linkedin.com',\n",
    "}\n",
    "\n",
    "# Initialize a Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Maximize the browser window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Add the LinkedIn cookie to the WebDriver session\n",
    "driver.get(\"https://www.linkedin.com\")\n",
    "time.sleep(random.randint(60, 65))\n",
    "driver.add_cookie(cookies)\n",
    "\n",
    "# Create an empty DataFrame to store job information\n",
    "job_info = pd.DataFrame(columns=[\"Company Name\", \"Job Role\", \"Job Description\"])\n",
    "\n",
    "# Initialize a counter variable\n",
    "c = 0\n",
    "\n",
    "# Iterate through each company name in the DataFrame\n",
    "for cn in df[\"Name\"]:\n",
    "    # Construct the search URL for the company on LinkedIn\n",
    "    search_url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3856839658&keywords={cn}%20jobs&origin=SWITCH_SEARCH_VERTICAL\"\n",
    "    \n",
    "    # Navigate to the search URL\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Add a random delay to simulate human-like behavior\n",
    "    time.sleep(random.randint(2, 5))\n",
    "    \n",
    "    # Find all elements matching the specified CSS selector\n",
    "    job_elements = driver.find_elements(By.CSS_SELECTOR, \".scaffold-layout__list-container li[data-occludable-job-id]\")\n",
    "  \n",
    "    # Iterate over each element and extract the 'data-occludable-job-id' attribute\n",
    "    for item in job_elements:\n",
    "            job_id = item.get_attribute('data-occludable-job-id')\n",
    "            url = f\"https://www.linkedin.com/jobs/view/{job_id}/?eBP=NON_CHARGEABLE_CHANNEL&refId=y33Dar2%2Fd7Ug6IIJOMnUyg%3D%3D&trackingId=GjIBF2h2spZFKbIyLF6%2FWg%3D%3D&trk=flagship3_search_srp_jobs\"\n",
    "            \n",
    "            # Open the URL in a new tab\n",
    "            driver.execute_script(f\"window.open('{url}', '_blank');\")\n",
    "        \n",
    "            # Switch to the new tab\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            \n",
    "            time.sleep(random.randint(15, 20))\n",
    "        \n",
    "            # Find the job role element\n",
    "            role_element = driver.find_element(By.ID, \"ember45\")  \n",
    "            role = role_element.text\n",
    "        \n",
    "            # Find the job description element\n",
    "            description_element = driver.find_element(By.CSS_SELECTOR, \".mt4\")\n",
    "            description = description_element.text\n",
    "        \n",
    "            # Store the extracted information in the DataFrame\n",
    "            job_info.loc[c] = [cn, role, description]\n",
    "            c += 1\n",
    "            \n",
    "            print(job_info)\n",
    "            job_info.head()\n",
    "            job_info.to_excel(\"job_info.xlsx\", index=False)\n",
    "             \n",
    "            \n",
    "            # Switch back to the original tab\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "           \n",
    "        \n",
    "            # Add a random delay\n",
    "            time.sleep(random.randint(5, 9))\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "job_info.to_excel(\"job_info.xlsx\", index=False)\n",
    "\n",
    "# Display completion message\n",
    "print(\"Scraping completed!\")\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046b54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
