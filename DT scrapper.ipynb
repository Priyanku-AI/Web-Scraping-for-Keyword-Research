{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6bde1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 217 pages\n",
      "Scraping data in page: 1\n",
      "Found a total of 51 results on this page \n",
      "\n",
      "Scraping: 10/51 completed\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d0b688dc7da6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Scraping data in page: {page}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://internshala.com/jobs/page-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'internshala_jobs'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d0b688dc7da6>\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(link, file_name, page)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'button_container_card'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandleRequests\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://internshala.com'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "import requests, csv, io, re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "fields = ['Name', 'Company Name', 'Location', 'Start Date', 'Apply by', 'Applicants', 'Salary', 'Number of Openings', 'Website Link', 'Internship Details']\n",
    "\n",
    "def handleRequests(query):\n",
    "    '''Returns HTML document'''\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36\"}\n",
    "    try:\n",
    "        request = requests.get(query, headers=headers, allow_redirects=False)\n",
    "        return request.text\n",
    "    except Exception:\n",
    "        raise ConnectionError(\"Error occured while fetching data from the web, please try checking the internet connection.\")\n",
    "\n",
    "def getSoup(data):\n",
    "    '''Returns parsed Soup Object from html text'''\n",
    "    return BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "def slugify(s, separator='-'):\n",
    "  s = s.lower().strip()\n",
    "  s = re.sub(r'[^\\w\\s-]', '', s)\n",
    "  s = re.sub(r'[\\s_-]+', separator, s)\n",
    "  s = re.sub(r'^-+|-+$', '', s)\n",
    "  return s\n",
    "\n",
    "def scrape(link, file_name='internshala_internships', page=1):\n",
    "    writer = io.open(f'{file_name}.csv', 'a', encoding='utf-8')\n",
    "    csvwriter = csv.writer(writer)\n",
    "    csvwriter.writerow(fields)\n",
    "\n",
    "    data = handleRequests(link)\n",
    "    soup = getSoup(data)\n",
    "\n",
    "    results = soup.find('div', attrs={'id': 'internship_list_container_' + str(page)}).find_all('div', attrs={'class': 'individual_internship'})\n",
    "    print(f'Found a total of {len(results)} results on this page \\n')\n",
    "    count = 1\n",
    "    total = len(results)\n",
    "    entries = []\n",
    "    for each in results:\n",
    "        link = each.find('div', attrs={'class': 'button_container_card'}).a['href']\n",
    "\n",
    "        page = handleRequests('https://internshala.com' + link);\n",
    "        page_content = getSoup(page)\n",
    "\n",
    "        details_container = page_content.find('div', attrs={'class': 'detail_view'})\n",
    "        internship_meta = details_container.find('div', attrs={'class': 'individual_internship'}).find('div', attrs={'class': 'internship_meta'})\n",
    "        individual_internship_details = internship_meta.find('div', attrs={'class': 'internship_other_details_container'})\n",
    "        internship_details_container = details_container.find('div', attrs={'class': 'internship_details'})\n",
    "\n",
    "\n",
    "        internship_name = internship_meta.find('span', attrs={'class': 'profile_on_detail_page'})\n",
    "        company_name = internship_meta.find('div', attrs={'class': 'company_name'})\n",
    "\n",
    "        company_location = internship_meta.find('div', attrs={'class': 'individual_internship_details'}).find('p', attrs={'id': 'location_names'})\n",
    "        stipend = individual_internship_details.find_all('div', attrs={'class': 'other_detail_item_row'})[0].find_all('div', attrs={'class': 'other_detail_item'})[1].find('div', attrs={'class': 'item_body'})\n",
    "        internship_details = internship_details_container.find_all('div')\n",
    "        website_link = internship_details_container.find('div', attrs={'class': 'website_link'})\n",
    "        \n",
    "        internship_start_date = individual_internship_details.find('div', attrs={'id': 'start-date-first'})\n",
    "        # internship_duration = individual_internship_details.find_all('div', attrs={'class': 'other_detail_item_row'})[0].find_all('div', attrs={'class': 'other_detail_item'})[1].find('div', attrs={'class': 'item_body'})\n",
    "        internship_applyby_date = individual_internship_details.find_all('div', attrs={'class': 'other_detail_item_row'})[1].find('div', attrs={'class': 'item_body'})\n",
    "        internship_applicants = details_container.find('div', attrs={'class', 'applications_message'})\n",
    "\n",
    "        number_of_openings = internship_details_container.find_all('div', attrs={'class': 'text-container'})[-1]\n",
    "        \n",
    "        INTERNSHIP = []\n",
    "\n",
    "        if (internship_name):\n",
    "            INTERNSHIP.append(internship_name.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (company_name):\n",
    "            INTERNSHIP.append(company_name.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (company_location):\n",
    "            INTERNSHIP.append(company_location.span.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (internship_start_date):\n",
    "            INTERNSHIP.append(internship_start_date.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        # if (internship_duration):\n",
    "        #     INTERNSHIP.append(internship_duration.get_text(\" \", strip=True))\n",
    "        # else:\n",
    "        #     INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (internship_applyby_date):\n",
    "            INTERNSHIP.append(internship_applyby_date.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (internship_applicants):\n",
    "            INTERNSHIP.append(internship_applicants.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (stipend):\n",
    "            INTERNSHIP.append(stipend.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (number_of_openings):\n",
    "            INTERNSHIP.append(number_of_openings.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (website_link):\n",
    "            INTERNSHIP.append(website_link.a['href'])\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        if (internship_details):\n",
    "            details = ''\n",
    "            for divs in internship_details:\n",
    "                details += divs.get_text(\" \", strip=True) + '\\n\\n'\n",
    "\n",
    "            INTERNSHIP.append(details)\n",
    "        else:\n",
    "            INTERNSHIP.append('Not Available')\n",
    "\n",
    "        csvwriter.writerow(INTERNSHIP)\n",
    "\n",
    "        print(f'Scraping: {count}/{total} completed', end='\\r')\n",
    "        count += 1\n",
    "\n",
    "    print(f'Completed: {count - 1}/{total}')\n",
    "    # input(\"Scraping completed successfully, press any key to exit...\")\n",
    "\n",
    "home_page = handleRequests('https://internshala.com/jobs/');\n",
    "home_page_content = getSoup(home_page)\n",
    "total_pages = home_page_content.find('div', attrs={'id': 'pagination'}).find('div', attrs={'class': 'page_number'}).find('span', attrs={'id': 'total_pages'}).get_text(\" \", strip=True)\n",
    "total_pages = int(total_pages)\n",
    "print(f'Found a total of {total_pages} pages')\n",
    "\n",
    "for x in range(total_pages + 1):\n",
    "    page = x + 1\n",
    "    print(f'Scraping data in page: {page}')\n",
    "    url = 'https://internshala.com/jobs/page-' + str(page)\n",
    "    scrape(url, 'internshala_jobs' + '_' + str(page), page)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4613cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
