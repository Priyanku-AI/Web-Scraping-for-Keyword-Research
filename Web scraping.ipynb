{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174f5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4d660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f4ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090d326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'124.0.6367.91'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.capabilities['chrome']['chromedriverVersion'].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19adbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_driver = '\\\\Users\\\\91700\\\\Downloads\\\\chromedriver-win64\\\\chromedriver'\n",
    "# may be required sometime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50989697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from selenium import webdriver  # For automating web browser interactions\n",
    "from selenium.webdriver.common.by import By  # For locating elements on web pages\n",
    "from bs4 import BeautifulSoup  # For parsing HTML and XML documents\n",
    "import time  # For adding delays in the script\n",
    "import warnings  # For managing warning messages\n",
    "import pandas as pd  # For working with data in tabular format\n",
    "from tqdm import tqdm  # For displaying progress bars\n",
    "import csv  # For reading and writing CSV files\n",
    "import random  # For generating random numbers\n",
    "import datetime  # For working with dates and times\n",
    "\n",
    "# Ignore any warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read the Excel file containing company names into a DataFrame\n",
    "df = pd.read_excel(\"Company_names.xlsx\")\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.head(10)\n",
    "\n",
    "# Read the LinkedIn authentication information (li_at cookie) from a text file\n",
    "with open(\"config.txt\", 'r', encoding=\"utf-8\") as f1:\n",
    "    lines = f1.readlines()\n",
    "li_at = lines[0]\n",
    "\n",
    "# Define the LinkedIn cookie\n",
    "cookies = {\n",
    "    'name': 'li_at',\n",
    "    'value': li_at,\n",
    "    'domain': '.linkedin.com',\n",
    "}\n",
    "\n",
    "# Initialize a Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the LinkedIn login page\n",
    "driver.get(\"https://www.linkedin.com\")\n",
    "time.sleep(random.randint(60,65))\n",
    "# Maximize the browser window\n",
    "driver.maximize_window()\n",
    "\n",
    "# Add the LinkedIn cookie to the WebDriver session\n",
    "driver.add_cookie(cookies)\n",
    "\n",
    "# Create an empty DataFrame to store company information\n",
    "transfer_sheet = pd.DataFrame(columns=[\"Company Name\", \"About\"])\n",
    "\n",
    "# Initialize a counter variable\n",
    "c = 0\n",
    "\n",
    "# Iterate through each company name in the DataFrame\n",
    "for cn in df[\"Name\"]:\n",
    "    # Construct the search URL for the company on LinkedIn\n",
    "    search_url = f\"https://www.linkedin.com/search/results/companies/?keywords={cn}&origin=SWITCH_SEARCH_VERTICAL&sid=7bb\"\n",
    "    \n",
    "    # Navigate to the search URL\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Add a random delay to simulate human-like behavior\n",
    "    time.sleep(random.randint(2, 5))\n",
    "    \n",
    "    try:\n",
    "        # Find the first search result link for the company\n",
    "        jc = driver.find_elements(By.CSS_SELECTOR, \".reusable-search__result-container a.app-aware-link\")\n",
    "        elems = list(jc)\n",
    "        lnks = elems[0].get_attribute('href') \n",
    "        \n",
    "        # Navigate to the company page\n",
    "        driver.get(lnks)\n",
    "        \n",
    "        # Add a random delay\n",
    "        time.sleep(random.randint(3, 7))\n",
    "        \n",
    "        try:\n",
    "            # Navigate to the \"About\" section of the company page\n",
    "            a = \"\"\n",
    "            for i in driver.find_elements(By.CSS_SELECTOR, \".org-page-navigation__item a\"):\n",
    "                x1 = i.get_attribute('href')\n",
    "                if 'about' in str(x1):\n",
    "                    a = x1\n",
    "            driver.get(a)\n",
    "        except:\n",
    "            print(\"Link not Found\")\n",
    "        \n",
    "        # Add a random delay\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # Extract information about the company\n",
    "        b = \"\"\n",
    "        elem2 = driver.find_elements(By.CSS_SELECTOR, \".overflow-hidden dd\")\n",
    "        for k in elem2:\n",
    "            b += \" \" + k.text\n",
    "        \n",
    "        # Store the extracted information in the DataFrame\n",
    "        transfer_sheet.loc[c] = [cn, b]\n",
    "        c += 1\n",
    "        \n",
    "        # Write the DataFrame to an Excel file\n",
    "        transfer_sheet.to_excel(r\"C:\\Users\\91700\\Desktop\\DT\\Scrapper\\data.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "        \n",
    "        # Add a random delay\n",
    "        time.sleep(random.randint(1, 5))\n",
    "    \n",
    "    except:\n",
    "        # If company information cannot be retrieved, mark it as \"No results\" in the DataFrame\n",
    "        transfer_sheet.loc[c] = [cn, \"No results\"]\n",
    "        transfer_sheet.to_excel(r\"C:\\Users\\91700\\Desktop\\DT\\Scrapper\\data.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "\n",
    "# End of the loop\n",
    "\n",
    "# Display completion message\n",
    "print(\"Scraping completed!\")\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cec6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99618862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
